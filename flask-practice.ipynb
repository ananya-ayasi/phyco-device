from werkzeug.wrappers import Request, Response
from flask import Flask

app= Flask(__name__) 
#Flask constructor takes the name of current module (__name__) as argument.

@app.route('/')
#The route() function of the Flask class is a decorator, 
#which tells the application which URL should call the associated function.
def hello():
       return "Hello World"

if __name__ == '__main__':
           from werkzeug.serving import run_simple
           run_simple('localhost',9000,app)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping
import pandas as pd
import io
import os
import requests
import numpy as np
from sklearn import metrics


dataFrame= pd.read_csv(r'auto-mpg.csv', na_values=['NA', '?'])

dataFrame.head()

dataFrame['horsepower']=dataFrame['horsepower'].fillna(dataFrame['horsepower'].median())

x= dataFrame[['cylinders','displacement','horsepower','weight','acceleration','year','origin']].values
y= dataFrame['mpg'].values


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.25, random_state=42)
#test size implies 25% will be test data and the rest for training.
#random_state is to ensure consistency -it is recommended to use the parameter to produce the same results across a different run.


model= Sequential()
model.add(Dense(25, input_dim=x.shape[1], activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')

monitor= EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto', restore_best_weights=True)
#This is to stop the training if the loss has reached "1e-3" and doesn't change even after "5" iterations and to restore the best version after stopping.
#verbose=1 shows the progress of the epochs

model.fit(x_train, y_train, validation_data=(x_text, y_test), callbacks=[monitor], verbose=2, epochs=1000)
